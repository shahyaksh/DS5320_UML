{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3717cd84-d9a5-4ae0-a7d9-91337b868dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd86066-2d10-45e0-ae2f-c7aa040bf458",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32958a06-a89c-430a-9d3f-0d057404b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class GaussianMixtureModel:\n",
    "    def __init__(self, n_gaussians, max_iter=100, tolerence=1e-5):\n",
    "\n",
    "        self.n_gaussians = n_gaussians\n",
    "        self.max_iter = max_iter\n",
    "        self.tolerence = tolerence\n",
    "        self.means = None\n",
    "        self.covariances = None\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X):\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.weights =np.random.dirichlet(alpha=np.ones(self.n_gaussians))  \n",
    "        self.means = X[np.random.choice(n_samples, self.n_gaussians, replace=False)]  \n",
    "        self.covariances = [np.eye(n_features) for _ in range(self.n_gaussians)]  \n",
    "\n",
    "        prev_log_likelihood = 0\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            # Compute responsibilities\n",
    "            responsibilities = self.e_step(X)\n",
    "\n",
    "            # Update parameters\n",
    "            self.m_step(X, responsibilities)\n",
    "\n",
    "            # Get log-likelihood\n",
    "            log_likelihood = self.get_log_likelihood(X)\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.abs(log_likelihood - prev_log_likelihood) < self.tolerence:\n",
    "                print(f\"It took {iteration} iterations to converge\")\n",
    "                break\n",
    "\n",
    "            prev_log_likelihood = log_likelihood\n",
    "\n",
    "    def e_step(self, X):\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        responsibilities = np.zeros((n_samples, self.n_gaussians))\n",
    "\n",
    "        for k in range(self.n_gaussians):\n",
    "            # Compute the probability density function for each component\n",
    "            responsibilities[:, k] = self.weights[k] * multivariate_normal.pdf(\n",
    "                X, mean=self.means[k], cov=self.covariances[k]\n",
    "            )\n",
    "\n",
    "        # Normalize responsibilities\n",
    "        responsibilities /= np.sum(responsibilities, axis=1, keepdims=True)\n",
    "        return responsibilities\n",
    "\n",
    "    def m_step(self, X, responsibilities):\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Update weights\n",
    "        self.weights = np.mean(responsibilities, axis=0)\n",
    "\n",
    "        # Update means\n",
    "        for k in range(self.n_gaussians):\n",
    "            self.means[k] = np.sum(responsibilities[:, k].reshape(-1, 1) * X, axis=0) / np.sum(responsibilities[:, k])\n",
    "\n",
    "        # Update covariances\n",
    "        for k in range(self.n_gaussians):\n",
    "            diff = X - self.means[k]\n",
    "            self.covariances[k] = (\n",
    "                np.dot((responsibilities[:, k].reshape(-1, 1) * diff).T, diff) / np.sum(responsibilities[:, k])\n",
    "            )\n",
    "\n",
    "    def get_log_likelihood(self, X):\n",
    "\n",
    "        likelihood = np.zeros((X.shape[0], self.n_gaussians))\n",
    "        for k in range(self.n_gaussians):\n",
    "            likelihood[:, k] = self.weights[k] * multivariate_normal.pdf(\n",
    "                X, mean=self.means[k], cov=self.covariances[k]\n",
    "            )\n",
    "        return np.sum(np.log(np.sum(likelihood, axis=1)))\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        responsibilities = self.e_step(X)\n",
    "        return np.argmax(responsibilities, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5db0b5-2406-4508-81ed-283334e48bd4",
   "metadata": {},
   "source": [
    "#### Question A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cdbd185-a4f9-4f13-91dc-94f41c33b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_data_2 = pd.read_csv('2gaussian.txt',sep=' ',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f756114-e7d2-469d-a7ce-534350ed3a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "GMM_algo = GaussianMixtureModel(n_gaussians=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b35f5b-251d-479d-9fff-ebec3fdc3ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 14 iterations to converge\n"
     ]
    }
   ],
   "source": [
    "X = gaussian_data_2.values\n",
    "GMM_algo.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fe3620-c36b-49a5-a82f-d7276946bd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33478522, 0.66521478])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMM_algo.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b7fa01-a827-4ba4-84d1-452d9dcadd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.99406954, 3.05210401],\n",
       "       [7.01311596, 3.9831157 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMM_algo.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "638b8e28-1a71-42e7-9305-e7f5aed961c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.01013134, 0.02720261],\n",
       "        [0.02720261, 2.93787134]]),\n",
       " array([[0.97481532, 0.49750231],\n",
       "        [0.49750231, 1.00116963]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMM_algo.covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732aab29-1296-455f-a4c3-e49b7d940b92",
   "metadata": {},
   "source": [
    "#### Question B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d7fb76-4bab-4f30-8f26-771e749afcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 82 iterations to converge\n"
     ]
    }
   ],
   "source": [
    "gaussian_data_3 = pd.read_csv('3gaussian.txt',sep=' ',header=None)\n",
    "GMM_algo = GaussianMixtureModel(n_gaussians=3)\n",
    "X = gaussian_data_3.values\n",
    "GMM_algo.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9bf2033-aa6b-4cb6-b3b3-a6ba719b1b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20563136, 0.29843228, 0.49593636])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMM_algo.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b883b45a-e2c7-4bae-9042-7e2e3af1ac00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.03984489, 3.0489184 ],\n",
       "       [7.02159479, 4.01547869],\n",
       "       [5.01179863, 7.00153459]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMM_algo.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e55338f-6954-4acd-9576-9fdced3c2590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.02862002, 0.02710779],\n",
       "        [0.02710779, 3.38555991]]),\n",
       " array([[0.99035672, 0.50093779],\n",
       "        [0.50093779, 0.99564625]]),\n",
       " array([[0.97962786, 0.18510425],\n",
       "        [0.18510425, 0.97446071]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMM_algo.covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55bbdab-7a75-4216-bff8-768a60ff8271",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5f15c36-bd9f-4901-adf1-d3c265dde59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "\n",
    "class BinomialMixtureModel:\n",
    "    def __init__(self, n_binomials, max_iter=100, tol=1e-6):\n",
    "\n",
    "        self.n_binomials = n_binomials\n",
    "        self.D = None  # Number of flips\n",
    "        self.max_iter = max_iter\n",
    "        self.tolerence = tol\n",
    "        self.pi = None  # probability of selecting a coin\n",
    "        self.p = None  # probability of occurence of heads\n",
    "\n",
    "    def fit(self, X):\n",
    "\n",
    "        n_samples,self.D = X.shape  \n",
    "        X = X.sum(axis=1)\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        self.pi =  np.random.dirichlet(alpha=np.ones(self.n_binomials)) # Mixing coefficients\n",
    "        self.p = np.random.uniform(low=0.2, high=0.8, size=self.n_binomials)  # Bias probabilities for each coin\n",
    "\n",
    "        prev_log_likelihood = 0\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            # Compute responsibilities\n",
    "            responsibilities = self.e_step(X)\n",
    "\n",
    "            #  Update parameters\n",
    "            self.m_step(X, responsibilities)\n",
    "\n",
    "            # Get log-likelihood\n",
    "            log_likelihood = self.get_log_likelihood(X)\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.abs(log_likelihood - prev_log_likelihood) < self.tolerence:\n",
    "                print(f\"It took {iteration} iterations to converge\")\n",
    "                break\n",
    "\n",
    "            log_likelihood_prev = log_likelihood\n",
    "\n",
    "    def e_step(self, X):\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        responsibilities = np.zeros((n_samples, self.n_binomials))\n",
    "\n",
    "        for k in range(self.n_binomials):\n",
    "            responsibilities[:, k] = self.pi[k] * binom.pmf(X, self.D, self.p[k])\n",
    "\n",
    "        # Normalize responsibilities\n",
    "        responsibilities /= responsibilities.sum(axis=1, keepdims=True)\n",
    "        return responsibilities\n",
    "\n",
    "    def m_step(self, X, responsibilities):\n",
    "  \n",
    "        # Update mixing coefficients\n",
    "        self.pi = responsibilities.mean(axis=0)\n",
    "\n",
    "        # Update bias probabilities\n",
    "        for k in range(self.n_binomials):\n",
    "            self.p[k] = np.sum(responsibilities[:, k] * X) / (self.D * np.sum(responsibilities[:, k]))\n",
    "\n",
    "    def get_log_likelihood(self, X):\n",
    "\n",
    "        likelihood = np.zeros((X.shape[0], self.n_binomials))\n",
    "        for k in range(self.n_binomials):\n",
    "            likelihood[:, k] = self.pi[k] * binom.pmf(X, self.D, self.p[k])\n",
    "\n",
    "        return np.sum(np.log(likelihood.sum(axis=1)))\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        responsibilities = self.e_step(X)\n",
    "        return np.argmax(responsibilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e03533e7-c493-4edc-8fe1-26607a8fe679",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_flips_outcome=pd.read_csv('coin_flips_outcome.txt',sep=' ',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4c88f3b-8930-4613-88b6-19ccd75d6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMM_algo = BinomialMixtureModel(n_binomials=3)\n",
    "X = coin_flips_outcome.values\n",
    "BMM_algo.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7b8e9ad-2aa6-42a7-aa1e-acc1a177cef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated selection probabilities (pi): [0.17855768 0.51462834 0.30681398]\n",
      "Estimated bias probabilities (p): [0.93172853 0.61003783 0.23691867]\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated selection probabilities (pi):\", BMM_algo.pi)\n",
    "print(\"Estimated bias probabilities (p):\", BMM_algo.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1c69c-e7a9-4db3-abbd-d3f9497f1d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
