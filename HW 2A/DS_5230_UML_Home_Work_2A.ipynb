{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7TbvBq3g1Ke5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2thCQkYJ16wU"
   },
   "outputs": [],
   "source": [
    "newsgroups_data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjZyHpIQ11cu",
    "outputId": "34d77a62-d851-44d1-ba32-5c369926ba3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 60000\n",
      "Image shape: (10000, 28, 28)\n",
      "Image shape: (28, 28)\n",
      "First label: 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_images(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Read the magic number and metadata\n",
    "        magic_number = int.from_bytes(f.read(4), byteorder='big')  # Magic number\n",
    "        num_images = int.from_bytes(f.read(4), byteorder='big')    # Number of images\n",
    "        num_rows = int.from_bytes(f.read(4), byteorder='big')      # Rows per image\n",
    "        num_cols = int.from_bytes(f.read(4), byteorder='big')      # Columns per image\n",
    "\n",
    "        # Read the image data\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        images = images.reshape(num_images, num_rows, num_cols)    # Reshape into 3D array\n",
    "    return images\n",
    "\n",
    "def load_labels(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Read the magic number and metadata\n",
    "        magic_number = int.from_bytes(f.read(4), byteorder='big')  # Magic number\n",
    "        num_labels = int.from_bytes(f.read(4), byteorder='big')    # Number of labels\n",
    "\n",
    "        # Read the label data\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "# Example usage\n",
    "\n",
    "train_images_file = 'Mnist/train-images.idx3-ubyte'\n",
    "train_labels_file = 'Mnist/train-labels.idx1-ubyte'\n",
    "test_images_file = 'Mnist/t10k-images.idx3-ubyte'\n",
    "test_labels_file = 'Mnist/t10k-labels.idx1-ubyte'\n",
    "\n",
    "mnist_train_images = load_images(train_images_file)\n",
    "mnist_train_labels = load_labels(train_labels_file)\n",
    "mnist_test_images = load_images(test_images_file)\n",
    "mnist_test_labels = load_labels(test_labels_file)\n",
    "\n",
    "\n",
    "print(f\"Number of images: {mnist_train_images.shape[0]}\")\n",
    "print(f\"Image shape: {mnist_test_images.shape[0:]}\")  # Rows x Columns\n",
    "print(f\"Image shape: {mnist_train_images.shape[1:]}\")  # Rows x Columns\n",
    "print(f\"First label: {mnist_train_labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 60000\n",
      "Image shape: (10000, 28, 28)\n",
      "Image shape: (28, 28)\n",
      "First label: 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_images_file = 'Fashion_Mnist/train-images-idx3-ubyte'\n",
    "train_labels_file = 'Fashion_Mnist/train-labels-idx1-ubyte'\n",
    "test_images_file = 'Fashion_Mnist/t10k-images-idx3-ubyte'\n",
    "test_labels_file = 'Fashion_Mnist/t10k-labels-idx1-ubyte'\n",
    "\n",
    "fashion_mnist_train_images = load_images(train_images_file)\n",
    "fashion_mnist_train_labels = load_labels(train_labels_file)\n",
    "fashion_mnist_test_images = load_images(test_images_file)\n",
    "fashion_mnist_test_labels = load_labels(test_labels_file)\n",
    "\n",
    "\n",
    "print(f\"Number of images: {fashion_mnist_train_images.shape[0]}\")\n",
    "print(f\"Image shape: {fashion_mnist_test_images.shape[0:]}\")  # Rows x Columns\n",
    "print(f\"Image shape: {fashion_mnist_train_images.shape[1:]}\")  # Rows x Columns\n",
    "print(f\"First label: {fashion_mnist_train_labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_2wnWjEDVKm"
   },
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WadUhiuz67sW"
   },
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbw8mIYQDaRs"
   },
   "source": [
    "\n",
    "The objective function in K-Means clustering is to minimize the within-cluster sum of squared distances:\n",
    "\n",
    "$$\n",
    "J(\\pi, \\mu) = \\sum_{i=1}^{N} \\sum_{k=1}^{K} \\pi_{ik} \\| x_i - \\mu_k \\|^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ x_i $ is the $ i $-th data point,\n",
    "- $ \\mu_k $ is the centroid of cluster $ k $,\n",
    "- $ \\pi_{ik} $ is the membership indicator:  \n",
    "\n",
    "## E-Step Update Rule\n",
    "\n",
    "In every E step we calculate distance of each point in our dataset to all centroids and update $ \\pi_{ik} $ as follows:\n",
    "\n",
    "$$\n",
    "\\pi_{ik} =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } k = \\arg \\min_{j} \\| x_i - \\mu_j \\|^2 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "## Proof that this approach reaches minimum\n",
    "\n",
    "our objective here is to minimize the assignment cost to each of the centroid $ \\mu_k $ for each data point $ x_i $:\n",
    "\n",
    "$$\n",
    "\\min_{\\pi_{ik}} \\sum_{k=1}^{K} \\pi_{ik} \\| x_i - \\mu_k \\|^2\n",
    "$$\n",
    "\n",
    "As $ \\pi_{ik} $ has only two values 0 or 1, if we assign a point to a cluster $ k $ were it's distance from point ${x_{i}}$ is minimum that is,\n",
    "\n",
    "$$\n",
    "\\min_k \\| x_i - \\mu_k \\|^2\n",
    "$$\n",
    "\n",
    "If we assign all the points such that the distance to the centroid it is assigned to is minimum our overall objective funtion reaches to it's minimum, which will not be the case when even a single point is assigned to any other cluster from which it's distance is not minimum.\n",
    "\n",
    "Thus, the assignment:\n",
    "\n",
    "$$\n",
    "\\pi_{ik} = 1 \\quad \\text{if } k = \\arg \\min_{j} \\| x_i - \\mu_j \\|^2\n",
    "$$\n",
    "\n",
    "achieves global minimum for the current cluster centroids $ \\mu_k $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOQPfwzuEGiI"
   },
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nAHqNCsEHZD"
   },
   "source": [
    "The K-Means clustering objective is to minimize the within-cluster sum of squared distances:\n",
    "\n",
    "$$\n",
    "J(\\pi, \\mu) = \\sum_{i=1}^{N} \\sum_{k=1}^{K} \\pi_{ik} \\| x_i - \\mu_k \\|^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ x_i $  is the $ i $-th data point,\n",
    "- $ \\mu_k $ is the centroid of cluster $ k $,\n",
    "- $ \\pi_{ik} $ is the membership indicator:\n",
    "\n",
    "  $$\n",
    "  \\pi_{ik} =\n",
    "  \\begin{cases}\n",
    "  1 & \\text{if } x_i \\text{ is assigned to cluster } k \\\\\n",
    "  0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "  $$\n",
    "\n",
    "## M-Step Update Rule\n",
    "\n",
    "In the M-step, given the current cluster assignments $ \\pi_{ik} $, the goal is to find the optimal centroids $ \\mu_k $ that minimize the objective function:\n",
    "\n",
    "$$\n",
    "\\min_{\\mu_k} \\sum_{i=1}^{N} \\pi_{ik} \\| x_i - \\mu_k \\|^2\n",
    "$$\n",
    "\n",
    "Taking the derivative of the objective function with respect to $ \\mu_k $:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\mu_k} \\sum_{i=1}^{N} \\pi_{ik} \\| x_i - \\mu_k \\|^2 = \\sum_{i=1}^{N} \\pi_{ik} 2 ( \\mu_k - x_i )\n",
    "$$\n",
    "\n",
    "To minimize we need to set the partial derivative of objective function to zero:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{N} \\pi_{ik} ( \\mu_k - x_i ) = 0\n",
    "$$\n",
    "\n",
    "Rearranging this equation we get:\n",
    "\n",
    "$$\n",
    "\\mu_k \\sum_{i=1}^{N} \\pi_{ik} = \\sum_{i=1}^{N} \\pi_{ik} x_i\n",
    "$$\n",
    "\n",
    "We get:\n",
    "\n",
    "$$\n",
    "\\mu_k = \\frac{\\sum_{i=1}^{N} \\pi_{ik} x_i}{\\sum_{i=1}^{N} \\pi_{ik}}\n",
    "$$\n",
    "\n",
    "From this equation we can say that the new $\\mu_k$ is the average of all the points assigned to it. Hence, after some iteration we will see no update which we can consider as a stopping criteria or can say we the objective function has reached the global minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wM1SIchR765o"
   },
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Bj6ue_u7_fd"
   },
   "source": [
    "In K-Means algorithm it is never the case where the E and M Step generate $\\mu_k$ or $\\pi_{ik}$ such that it increase the value of objective function. That means it can only decrease the objective function or there is no change in it's value which is the case when we can say that the algorithm has converged.<br>\n",
    "\n",
    "The main thing in K-Means algorithm is that it depends on the initial selection of centroids. If centroids are not selected properly the algorithm will converge to it's local minima.<br>\n",
    "\n",
    "For, example let's consider MNIST dataset it contains digits if we do random initialization of centroids at first than it may be possible that multiple centroids carry the same number. Which will result into a biased case where it will perform well for one class but not other. So, here if we select one centroid for each digit than the algorithm reaches it global maxima and performs very well.<br>\n",
    "\n",
    "Hence, we can say that the K-Means algorithm is always going to converge no matter what but we cann't say with confidence that it has converged to local or global minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mnist dataset\n",
    "def zero_mean_unit_variance_normalization(data):\n",
    "\n",
    "    mnist_data_normalized_with_unit_var = []\n",
    "    for image in data:\n",
    "        image = np.reshape(image,(784,))\n",
    "        pixel_value_mean = image.mean()\n",
    "        pixel_value_std = image.std()\n",
    "        # Shifting scale to [0,1]\n",
    "        image = (image-pixel_value_mean)/(pixel_value_std)\n",
    "        mnist_data_normalized_with_unit_var.append(image)\n",
    "    return mnist_data_normalized_with_unit_var\n",
    "\n",
    "mnist_train_images_normalized_with_unit_var = zero_mean_unit_variance_normalization(mnist_train_images)\n",
    "mnist_test_images_normalized_with_unit_var = zero_mean_unit_variance_normalization(mnist_test_images)\n",
    "fashion_mnist_train_images_normalized_with_unit_var = zero_mean_unit_variance_normalization(fashion_mnist_train_images)\n",
    "fashion_mnist_test_images_normalized_with_unit_var = zero_mean_unit_variance_normalization(fashion_mnist_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(mnist_train_images_normalized_with_unit_var).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8E7YAN3v2ej3"
   },
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard KMeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PiGzqj2A11nV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, n_clusters, batch_size=10,metric='euclidean',max_iter=100,random_state=42):\n",
    "\n",
    "        self.n_clusters = n_clusters\n",
    "        self.batch_size = batch_size \n",
    "        self.random_state = random_state\n",
    "        self.metric = metric\n",
    "        self.max_iter = max_iter\n",
    "        self.centroids = None \n",
    "        self.pi_matrix = None \n",
    "        self.labels_ = None  \n",
    "        self.X = None \n",
    "        self.dist_matrix = None \n",
    "        self.no_of_batches = None  \n",
    "    \n",
    "\n",
    "    def update_pi_matrix(self, X, no_of_batches, batch_size):\n",
    "\n",
    "        pi_matrix = np.zeros((X.shape[0], self.n_clusters))  \n",
    "        dist_matrix = np.zeros((X.shape[0], self.n_clusters)) \n",
    "        \n",
    "        for i in range(no_of_batches):\n",
    "            # Calculate start and end indices for the current batch\n",
    "            start = i * batch_size\n",
    "            end = min(start + batch_size, X.shape[0])\n",
    "\n",
    "            # Compute distances between centroids and data points in the current batch\n",
    "            \n",
    "\n",
    "            # Find the index of the closest centroid for each data point in the batch\n",
    "            if self.metric=='cosine':\n",
    "                # start_time = time.time()\n",
    "                similarity = cosine_similarity(X=self.centroids, Y=X[start:end])\n",
    "                dist_matrix[start:end, :] = similarity.T\n",
    "                index_of_closest_centroids = np.argmax(similarity, axis=0)\n",
    "                # end_time = time.time()\n",
    "                \n",
    "            else:\n",
    "                distances = pairwise_distances(X=self.centroids, Y=X[start:end], metric=self.metric)\n",
    "                index_of_closest_centroids = np.argmin(distances, axis=0)\n",
    "                dist_matrix[start:end, :] = distances.T\n",
    "\n",
    "            # Update the assignment matrix (pi_matrix) for the current batch\n",
    "            pi_matrix[np.arange(start, end), index_of_closest_centroids] = 1\n",
    "\n",
    "            # Update the distance matrix for the current batch\n",
    "            \n",
    "\n",
    "        return pi_matrix, dist_matrix\n",
    "\n",
    "    def update_centroids(self, X, pi_matrix):\n",
    "        \n",
    "        # Compute new centroids as the mean of data points assigned to each cluster\n",
    "        centroids = pi_matrix.T @ X\n",
    "        no_of_members = np.sum(pi_matrix, axis=0)[:, np.newaxis]  # Number of members in each cluster\n",
    "        centroids = np.divide(centroids, no_of_members, where=no_of_members != 0) \n",
    "        return centroids\n",
    "\n",
    "    def get_labels(self, pi_matrix):\n",
    "\n",
    "        return np.argmax(pi_matrix, axis=1)\n",
    "\n",
    "    def fit(self, X):\n",
    "\n",
    "        i = 0\n",
    "        self.X = X\n",
    "        np.random.seed(self.random_state)  # Set random seed for reproducibility\n",
    "        self.no_of_batches = math.ceil(X.shape[0] / self.batch_size)  # Calculate number of batches\n",
    "\n",
    "        # Initialize centroids by randomly selecting data points\n",
    "        self.centroids = X[np.random.choice(X.shape[0], self.n_clusters, replace=False)]\n",
    "\n",
    "        # Iterate until convergence or maximum iterations are reached\n",
    "        while i <= self.max_iter:\n",
    "            # Update assignment matrix (pi_matrix) and distance matrix\n",
    "            # start_time = time.time()\n",
    "            self.pi_matrix, self.dist_matrix = self.update_pi_matrix(X, self.no_of_batches, self.batch_size)\n",
    "            # end_time = time.time()\n",
    "            # exe_time = end_time-start_time\n",
    "            # print('Time for this iter:%.2f' % exe_time)\n",
    "\n",
    "            # Update centroids based on the current assignments\n",
    "            new_centroids = self.update_centroids(X, self.pi_matrix)\n",
    "\n",
    "            # Check for convergence (if centroids do not change)\n",
    "            if np.array_equal(self.centroids, new_centroids):\n",
    "                break\n",
    "\n",
    "            # Update centroids for the next iteration\n",
    "            self.centroids = new_centroids\n",
    "            i += 1\n",
    "\n",
    "        print(f'It took {i} iterations to converge')\n",
    "        self.labels_ = self.get_labels(self.pi_matrix)  # Assign final cluster labels\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        no_of_batches = math.ceil(X.shape[0] / 100)  # Use a fixed batch size of 100 for prediction\n",
    "        self.pi_matrix, self.dist_matrix = self.update_pi_matrix(X, no_of_batches, 100)\n",
    "        prediction = self.get_labels(self.pi_matrix)\n",
    "        return prediction\n",
    "\n",
    "    def gini_index(self, cf_matrix, by='row'):\n",
    "\n",
    "        gini_index_per_cluster = []\n",
    "        avg_gini_index = 0\n",
    "\n",
    "        for i in range(self.n_clusters):\n",
    "            if by == 'row':\n",
    "                no_of_members = np.sum(cf_matrix[i, :])  # Number of members in the cluster\n",
    "                prob = cf_matrix[i, :] / no_of_members if no_of_members > 0 else np.zeros(cf_matrix.shape[1])\n",
    "            else:\n",
    "                no_of_members = np.sum(cf_matrix[:, i])  # Number of members in the cluster\n",
    "                prob = cf_matrix[:, i] / no_of_members if no_of_members > 0 else np.zeros(cf_matrix.shape[1])\n",
    "\n",
    "            # Compute Gini index for the current cluster\n",
    "            gini_index_of_cluster = 1 - np.sum(prob ** 2)\n",
    "            gini_index_per_cluster.append(gini_index_of_cluster)\n",
    "            avg_gini_index += (gini_index_of_cluster * no_of_members)\n",
    "\n",
    "        # Compute weighted average Gini index\n",
    "        avg_gini_index = avg_gini_index / np.sum(cf_matrix)\n",
    "\n",
    "        return gini_index_per_cluster, avg_gini_index\n",
    "\n",
    "    def evaluate(self, y_true, y_pred):\n",
    "\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)  # Compute confusion matrix\n",
    "        gini_per_cluster, avg_gini = self.gini_index(cf_matrix)  # Compute Gini index\n",
    "        purity = self.purity_of_cluster(cf_matrix)  # Compute purity\n",
    "        sum_of_squares = self.calculating_sse()  # Compute sum of squared errors (SSE)\n",
    "\n",
    "        # Print evaluation metrics\n",
    "        print('Confusion Matrix:\\n', cf_matrix)\n",
    "        print('\\n Gini Index Per Cluster:\\n ', gini_per_cluster)\n",
    "        print('\\n Average Gini Index: %.2f' % avg_gini)\n",
    "        print('\\n Purity of the Cluster: %.2f' % purity)\n",
    "        print('\\n Sum Of Squares: %.2f' % sum_of_squares)\n",
    "\n",
    "    def purity_of_cluster(self, cf_matrix):\n",
    "\n",
    "        P_i = np.sum(np.max(cf_matrix, axis=1))  # Sum of the maximum values in each row\n",
    "        purity = P_i / np.sum(cf_matrix)  # Compute purity\n",
    "        return purity\n",
    "\n",
    "    def calculating_sse(self):\n",
    "\n",
    "        return np.sum(self.pi_matrix * (self.dist_matrix ** 2))  # Compute SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "\n",
    "class Soft_KMeans:\n",
    "    def __init__(self, n_clusters,beta=0.1,metric='euclidean',max_iter=100 ,batch_size=10, random_state=42):\n",
    "\n",
    "        self.beta = beta\n",
    "        self.n_clusters = n_clusters\n",
    "        self.metric=metric\n",
    "        self.batch_size=batch_size\n",
    "        self.max_iter=max_iter\n",
    "        self.random_state=random_state\n",
    "        self.X = None \n",
    "        self.centroids = None \n",
    "        self.pi_matrix = None \n",
    "        self.labels_ = None  \n",
    "        self.dist_matrix = None \n",
    "        self.no_of_batches = None  \n",
    "        \n",
    "        \n",
    "    def softmax_for_kmeans(self,distances):\n",
    "        exp_distances = np.exp(-self.beta*distances)\n",
    "        softmax_prob = exp_distances/np.sum(exp_distances,axis=0)\n",
    "        return softmax_prob\n",
    "        \n",
    "\n",
    "    def update_pi_matrix(self, X, no_of_batches, batch_size):\n",
    "\n",
    "\n",
    "        pi_matrix = np.zeros((X.shape[0], self.n_clusters))  \n",
    "        dist_matrix = np.zeros((X.shape[0], self.n_clusters)) \n",
    "\n",
    "        for i in range(no_of_batches):\n",
    "            # Calculate start and end indices for the current batch\n",
    "            start = i * batch_size\n",
    "            end = min(start + batch_size, X.shape[0])\n",
    "            \n",
    "            # Compute distances between centroids and data points in the current batch\n",
    "            distances = pairwise_distances(X=self.centroids, Y=X[start:end], metric=self.metric)\n",
    "            \n",
    "            # Update the distance matrix for the current batch\n",
    "            dist_matrix[start:end, :] = distances.T\n",
    "\n",
    "            # Update the assignment matrix (pi_matrix) for the current batch\n",
    "            pi_matrix[np.arange(start, end), :] = self.softmax_for_kmeans(distances.T)\n",
    "\n",
    "        return pi_matrix, dist_matrix\n",
    "\n",
    "    def update_centroids(self, X, pi_matrix):\n",
    "\n",
    "        # Compute new centroids as the mean of data points assigned to each cluster\n",
    "        centroids = pi_matrix.T @ X\n",
    "        sum_of_prob = np.sum(pi_matrix, axis=0)[:, np.newaxis]  # Number of members in each cluster\n",
    "        centroids = np.divide(centroids, sum_of_prob, where=sum_of_prob != 0) \n",
    "        return centroids\n",
    "    \n",
    "    def get_labels(self, pi_matrix):\n",
    "\n",
    "        return np.argmax(pi_matrix, axis=1)\n",
    "\n",
    "\n",
    "    def fit(self, X):\n",
    "\n",
    "        i = 0\n",
    "        self.X = X\n",
    "        np.random.seed(self.random_state)  # Set random seed for reproducibility\n",
    "        self.no_of_batches = math.ceil(X.shape[0] / self.batch_size)  # Calculate number of batches\n",
    "\n",
    "        # Initialize centroids by randomly selecting data points\n",
    "        self.centroids = X[np.random.choice(X.shape[0], self.n_clusters, replace=False)]\n",
    "\n",
    "        # Iterate until convergence or maximum iterations are reached\n",
    "        while i <= self.max_iter:\n",
    "            # Update assignment matrix (pi_matrix) and distance matrix\n",
    "            self.pi_matrix, self.dist_matrix = self.update_pi_matrix(X, self.no_of_batches, self.batch_size)\n",
    "\n",
    "            # Update centroids based on the current assignments\n",
    "            new_centroids = self.update_centroids(X, self.pi_matrix)\n",
    "\n",
    "            # Check for convergence (if centroids do not change)\n",
    "            if np.array_equal(self.centroids, new_centroids):\n",
    "                break\n",
    "\n",
    "            # Update centroids for the next iteration\n",
    "            self.centroids = new_centroids\n",
    "            i += 1\n",
    "\n",
    "        print(f'It took {i} iterations to converge')\n",
    "        self.labels_ = self.get_labels(self.pi_matrix)  # Assign final cluster labels\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        no_of_batches = math.ceil(X.shape[0] / 100)  # Use a fixed batch size of 100 for prediction\n",
    "        self.pi_matrix, self.dist_matrix = self.update_pi_matrix(X, no_of_batches, 100)\n",
    "        prediction = self.get_labels(self.pi_matrix)\n",
    "        return prediction\n",
    "\n",
    "    def gini_index(self, cf_matrix, by='row'):\n",
    "\n",
    "        gini_index_per_cluster = []\n",
    "        avg_gini_index = 0\n",
    "\n",
    "        for i in range(self.n_clusters):\n",
    "            if by == 'row':\n",
    "                no_of_members = np.sum(cf_matrix[i, :])  # Number of members in the cluster\n",
    "                prob = cf_matrix[i, :] / no_of_members if no_of_members > 0 else np.zeros(cf_matrix.shape[1])\n",
    "            else:\n",
    "                no_of_members = np.sum(cf_matrix[:, i])  # Number of members in the cluster\n",
    "                prob = cf_matrix[:, i] / no_of_members if no_of_members > 0 else np.zeros(cf_matrix.shape[1])\n",
    "\n",
    "            # Compute Gini index for the current cluster\n",
    "            gini_index_of_cluster = 1 - np.sum(prob ** 2)\n",
    "            gini_index_per_cluster.append(gini_index_of_cluster)\n",
    "            avg_gini_index += (gini_index_of_cluster * no_of_members)\n",
    "\n",
    "        # Compute weighted average Gini index\n",
    "        avg_gini_index = avg_gini_index / np.sum(cf_matrix)\n",
    "\n",
    "        return gini_index_per_cluster, avg_gini_index\n",
    "\n",
    "    def evaluate(self, y_true, y_pred):\n",
    "\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)  # Compute confusion matrix\n",
    "        gini_per_cluster, avg_gini = self.gini_index(cf_matrix)  # Compute Gini index\n",
    "        purity = self.purity_of_cluster(cf_matrix)  # Compute purity\n",
    "        sum_of_squares = self.calculating_sse()  # Compute sum of squared errors (SSE)\n",
    "\n",
    "        # Print evaluation metrics\n",
    "        print('Confusion Matrix:\\n', cf_matrix)\n",
    "        print('\\n Gini Index Per Cluster:\\n ', gini_per_cluster)\n",
    "        print('\\n Average Gini Index: %.2f' % avg_gini)\n",
    "        print('\\n Purity of the Cluster: %.2f' % purity)\n",
    "        print('\\n Sum Of Squares: %.2f' % sum_of_squares)\n",
    "\n",
    "    def purity_of_cluster(self, cf_matrix):\n",
    "\n",
    "        P_i = np.sum(np.max(cf_matrix, axis=1))  # Sum of the maximum values in each row\n",
    "        purity = P_i / np.sum(cf_matrix)  # Compute purity\n",
    "        return purity\n",
    "\n",
    "    def calculating_sse(self):\n",
    "\n",
    "        return np.sum(self.pi_matrix * (self.dist_matrix ** 2))  # Compute SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means For MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QCI88PWPGNp8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(mnist_train_images_normalized_with_unit_var)\n",
    "y = np.array(mnist_train_labels)\n",
    "X = X.reshape(X.shape[0],-1,)\n",
    "y = y.reshape(y.shape[0],-1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eEmUMzAwJD_l"
   },
   "outputs": [],
   "source": [
    "kmeans_mnist = KMeans(10,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJ2x_hxnJEBg",
    "outputId": "5d462945-3f86-4b95-94aa-f7befbd6fff0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 47 iterations to converge\n"
     ]
    }
   ],
   "source": [
    "kmeans_mnist.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ezZY4FlG1QPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  12  533    1  101  179   22   12 3871    0    8]\n",
      " [  15   46 2486   28    9    1   47    0 2764    7]\n",
      " [  29  115   73  304  185  120 3745   66   86   43]\n",
      " [ 114  808   10 3526   48   68  176   34   51   20]\n",
      " [1177  117   53    2  135 1914   24    8   32 1182]\n",
      " [ 134 2023   26 1673   98  186   45   94    7   54]\n",
      " [   0  334   29   29 3919  121  200   89   33    0]\n",
      " [1861   21   99    5    8  601   50   43   91 2239]\n",
      " [ 179 2534   49 1488   41  128   54   19   75  152]\n",
      " [1919   57   18   93    6 1324    9   31   36 1269]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.31820614021983407, 0.526405751577405, 0.37489700527709846, 0.4425063398812735, 0.6994334237689004, 0.6300560640489287, 0.3126064024378913, 0.6481139797883458, 0.6084319784834146, 0.6886446689377846]\n",
      "\n",
      " Average Gini Index: 0.52\n",
      "\n",
      " Purity of the Cluster: 0.59\n",
      "\n",
      " Sum Of Squares: 19516787.88\n"
     ]
    }
   ],
   "source": [
    "y_pred = kmeans_mnist.labels_\n",
    "kmeans_mnist.evaluate(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = kmeans_mnist.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  0 140   0  32  38   2   3 969   0   0]\n",
      " [  3   9 609   7   2   1  12   0 694   2]\n",
      " [  7  29  18  70  40  14 965  13  23  13]\n",
      " [ 22 216   1 934  17  20  42   4  18   2]\n",
      " [334  22  15   2  27 463  10   3   6 316]\n",
      " [ 37 508   6 406  25  45  15  21   4  14]\n",
      " [  0  79   4   8 975  23  46  22   6   1]\n",
      " [488   2  25   2   1 129  15  13  20 552]\n",
      " [ 43 611  21 350  11  37   8   4  18  29]\n",
      " [470  11   5  34   2 326   2  11   8 318]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.31445027163988315, 0.5243465830340546, 0.3384292937255077, 0.43354158272815735, 0.7022249101869839, 0.6338804735054482, 0.2913758694394256, 0.6392837597724514, 0.6091488843661428, 0.6949578024782661]\n",
      "\n",
      " Average Gini Index: 0.52\n",
      "\n",
      " Purity of the Cluster: 0.60\n",
      "\n",
      " Sum Of Squares: 4873648.89\n"
     ]
    }
   ],
   "source": [
    "kmeans_mnist.evaluate(y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For K=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 101 iterations to converge\n",
      "Confusion Matrix:\n",
      " [[   2   38    0  938  206    0    0    0    0    0]\n",
      " [  16   24 1291    1    7    0    0    0    0    0]\n",
      " [  12   41  134  123  882    0    0    0    0    0]\n",
      " [  74  106   66  989   41    0    0    0    0    0]\n",
      " [ 705  377   19    1   96    0    0    0    0    0]\n",
      " [  72  359   26  566   58    0    0    0    0    0]\n",
      " [   0    3   34   28 1099    0    0    0    0    0]\n",
      " [ 569  614   50    8    6    0    0    0    0    0]\n",
      " [ 103  474  148  364   43    0    0    0    0    0]\n",
      " [ 693  421   16   32   25    0    0    0    0    0]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.3410678414901388, 0.06991830649537834, 0.42792976667717675, 0.3852814437751201, 0.5479862096259487]\n",
      "\n",
      " Average Gini Index: 0.18\n",
      "\n",
      " Purity of the Cluster: 0.69\n",
      "\n",
      " Sum Of Squares: 5494638.71\n"
     ]
    }
   ],
   "source": [
    "kmeans_mnist = KMeans(5,5000)\n",
    "kmeans_mnist.fit(X_train)\n",
    "predict = kmeans_mnist.predict(X_test)\n",
    "kmeans_mnist.evaluate(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of Objective Function for K=5 is:5494638.71\n"
     ]
    }
   ],
   "source": [
    "print(\"Value of Objective Function for K=5 is:%.2f\"% kmeans_mnist.calculating_sse())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 101 iterations to converge\n",
      "Confusion Matrix:\n",
      " [[  0  61   1   5  32  14   8 482  21   0   0   2  11   0   0   0   0 529\n",
      "    2  16]\n",
      " [  2   2   8   6   5   0   1   0   0   0 658  67   0 580   0   0   2   0\n",
      "    0   8]\n",
      " [  0   3 440   7   3   1   8   0   4  10   6  20 181   6   4   0   2   9\n",
      "  480   8]\n",
      " [  0  19  17 298   3   2 512   0 279   2  11  31   5   0   2   5   7   3\n",
      "   16  64]\n",
      " [465  12   0   2  20   6   0   0   0  38   4  17  31  13   0 328 252   2\n",
      "    7   1]\n",
      " [ 11 325   1 113  16   3 142   5 210   5   3   5  10   2   1  21   7  13\n",
      "    1 187]\n",
      " [  1  34   1   4 566 453   0  10   6   0   1   0  62   4   0   1   0  16\n",
      "    2   3]\n",
      " [ 31   4   2   2   0   0   0   8   0 433  19  17  19  15 528  80  80   4\n",
      "    4   1]\n",
      " [ 13  25   6 177   6   1  28   5  64   8   5 323  10   9   2   8  14   2\n",
      "    7 419]\n",
      " [337   5   0  19   0   0   5   2  10 150  12   8  16   3  27 230 345   8\n",
      "    0  10]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.6304741713842221, 0.5682715523996875, 0.6779100603576416, 0.7328286376902742, 0.7276833119194205, 0.8127072527664367, 0.6080835724660785, 0.6904255859612388, 0.7521679007104596, 0.7800696821576628, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      " Average Gini Index: 0.70\n",
      "\n",
      " Purity of the Cluster: 0.40\n",
      "\n",
      " Sum Of Squares: 4394167.90\n"
     ]
    }
   ],
   "source": [
    "kmeans_mnist = KMeans(20,5000)\n",
    "kmeans_mnist.fit(X_train)\n",
    "predict = kmeans_mnist.predict(X_test)\n",
    "kmeans_mnist.evaluate(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of Objective Function for K=20 is:4394167.90\n"
     ]
    }
   ],
   "source": [
    "print(\"Value of Objective Function for K=20 is:%.2f\"% kmeans_mnist.calculating_sse())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft Kmeans for MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_mnist = Soft_KMeans(n_clusters=10,beta=1,batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 101 iterations to converge\n"
     ]
    }
   ],
   "source": [
    "kmeans_mnist.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  29  241  156   50  142  819  483 2727   77   15]\n",
      " [  32   64  310   15   32 3087   26    0 1836    1]\n",
      " [   4  129 1424   33  110 1977   89   96  896    8]\n",
      " [  23   38  328 1641   22  655 1618   88  410   32]\n",
      " [ 294  120  138  109  276 2976  129   97   21  484]\n",
      " [ 141  167  215  564   85 1597 1011  309  163   88]\n",
      " [   0 1243   76    4 1378 1751   26  206   70    0]\n",
      " [ 853   21  413   37   37 2545  155  107   63  787]\n",
      " [ 182   94  954  392   95 1733  447   92  540  190]\n",
      " [ 936   62  124  161  128 1967  198  107   22 1057]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.6236259035206018, 0.5545550557338381, 0.7012440723554327, 0.7443157860126999, 0.5676091180417844, 0.7811781944827879, 0.7095757459696939, 0.6808145121563964, 0.791008345652049, 0.7365088061531504]\n",
      "\n",
      " Average Gini Index: 0.69\n",
      "\n",
      " Purity of the Cluster: 0.46\n",
      "\n",
      " Sum Of Squares: 1552060.74\n"
     ]
    }
   ],
   "source": [
    "predict = kmeans_mnist.predict(X_train)\n",
    "kmeans_mnist.evaluate(y_train,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 101 iterations to converge\n",
      "Confusion Matrix:\n",
      " [[1497  500  261   91   90  100  154   91 1369  586]\n",
      " [1676  464  225  183  114   82  234  109 1698  618]\n",
      " [1422  407  214  162  134   65  251   89 1464  558]\n",
      " [1412  500  210  167  120   80  281  100 1486  499]\n",
      " [1437  399  135  204  106   46  236   82 1471  528]\n",
      " [1317  417  207  116  122   61  222   79 1283  516]\n",
      " [1401  402  170  172   94   67  241   81 1551  575]\n",
      " [1624  434  176  136  130   70  241   95 1488  624]\n",
      " [1119  432  189  147  123   78  424   68 1615  524]\n",
      " [1288  417  173  174  134   78  367   70 1490  571]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.7847075006853869, 0.7787140143179002, 0.7883518537465249, 0.7928519867082573, 0.777323374292707, 0.7902292467455244, 0.7788952252240613, 0.7788896600377342, 0.7941291917481017, 0.7970242863097379]\n",
      "\n",
      " Average Gini Index: 0.79\n",
      "\n",
      " Purity of the Cluster: 0.32\n",
      "\n",
      " Sum Of Squares: 2560193.66\n"
     ]
    }
   ],
   "source": [
    "# For Beta 0.1\n",
    "kmeans_mnist = Soft_KMeans(n_clusters=10,beta=0.1,batch_size=5000)\n",
    "kmeans_mnist.fit(X_train)\n",
    "predict = kmeans_mnist.predict(X_train)\n",
    "kmeans_mnist.evaluate(y_train,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 101 iterations to converge\n",
      "Confusion Matrix:\n",
      " [[  14  287  124   57   60  545  404 2719  522    7]\n",
      " [ 149  142 1056   17   33 2300   80    0 1620    6]\n",
      " [  15  176 1403   13   65 1501  306  130 1153    4]\n",
      " [  70   40  442 1358   16  435 1314  168  998   14]\n",
      " [ 415  138  165   73  165 2882  105  211   85  405]\n",
      " [ 182  230  186  615   69 1118  690  405  739  106]\n",
      " [   4 1000   83    2 1138 1601   10  315  600    1]\n",
      " [1120   22  504   28   29 1914  129  395   97  780]\n",
      " [ 298  148  602  348   80 1265  969  144  657  208]\n",
      " [1201   55  111  130   70 1657  106  291  103 1038]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.6335167577020357, 0.68896999901584, 0.7491953688606647, 0.7884466627989236, 0.5927168580354487, 0.8433279534498502, 0.7644089188052167, 0.7631326745438224, 0.8367480638185141, 0.7614653208825786]\n",
      "\n",
      " Average Gini Index: 0.74\n",
      "\n",
      " Purity of the Cluster: 0.38\n",
      "\n",
      " Sum Of Squares: 1644676.56\n"
     ]
    }
   ],
   "source": [
    "# For Beta 10\n",
    "kmeans_mnist = Soft_KMeans(n_clusters=10,beta=10,batch_size=5000)\n",
    "kmeans_mnist.fit(X_train)\n",
    "predict = kmeans_mnist.predict(X_train)\n",
    "kmeans_mnist.evaluate(y_train,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KMeans for Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(fashion_mnist_train_images_normalized_with_unit_var)\n",
    "y1 = np.array(fashion_mnist_train_labels)\n",
    "X1 = X1.reshape(X1.shape[0],-1,)\n",
    "y1 = y1.reshape(y1.shape[0],-1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_fashion_mnist = KMeans(10,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 101 iterations to converge\n"
     ]
    }
   ],
   "source": [
    "kmeans_fashion_mnist.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  19  404    1  101 3977    5   15  179   66    0]\n",
      " [   4   25 2427   20    0   14    4    8   75 2800]\n",
      " [  97  108   83  372   64   28   43  168 3741   86]\n",
      " [  83  998    8 3363   24   99   21   52  222   56]\n",
      " [1935   29   53    2   11 1125 1264  119   69   29]\n",
      " [ 194 1839   31 1469   99  115  176   84  342    8]\n",
      " [  94  236   32   28   91    0    1 3946  268   41]\n",
      " [ 560    9   99    7   45 2059 2081    6   59   78]\n",
      " [ 147 2628   67 1264   15  134  183   42  115   64]\n",
      " [1422   52   23   87   34 1826 1254    7   10   33]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.29472138820272886, 0.5248613133954957, 0.3809399366285886, 0.4898650246959919, 0.6914698041586236, 0.6967587396789698, 0.29948194605602385, 0.6442191051549363, 0.6037583315170387, 0.692058874254863]\n",
      "\n",
      " Average Gini Index: 0.53\n",
      "\n",
      " Purity of the Cluster: 0.59\n",
      "\n",
      " Sum Of Squares: 19527679.30\n"
     ]
    }
   ],
   "source": [
    "y_pred = kmeans_fashion_mnist.labels_\n",
    "kmeans_fashion_mnist.evaluate(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 43 iterations to converge\n",
      "Confusion Matrix:\n",
      " [[   8   59    2  989   98    0    0    0    0    0]\n",
      " [   5   27 1323    0   10    0    0    0    0    0]\n",
      " [  30  156   99   21  862    0    0    0    0    0]\n",
      " [  36 1058   49   15   47    0    0    0    0    0]\n",
      " [ 946    7   43    8  202    0    0    0    0    0]\n",
      " [ 164  602  118   29  151    0    0    0    0    0]\n",
      " [   2   16   32   27 1104    0    0    0    0    0]\n",
      " [1116    6   98   28   14    0    0    0    0    0]\n",
      " [ 150  645  293   10   94    0    0    0    0    0]\n",
      " [1064   45   51   12   29    0    0    0    0    0]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.2582149998204045, 0.060133370902601735, 0.4293297874835803, 0.22487904822575366, 0.3552951109570994]\n",
      "\n",
      " Average Gini Index: 0.13\n",
      "\n",
      " Purity of the Cluster: 0.81\n",
      "\n",
      " Sum Of Squares: 5480021.32\n"
     ]
    }
   ],
   "source": [
    "kmeans_fashion_mnist = KMeans(5,5000)\n",
    "kmeans_fashion_mnist.fit(X_train)\n",
    "predict = kmeans_fashion_mnist.predict(X_test)\n",
    "kmeans_fashion_mnist.evaluate(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of Objective Function for K=5 is: 5480021.32\n"
     ]
    }
   ],
   "source": [
    "print(\"Value of Objective Function for K=5 is: %.2f\"% kmeans_fashion_mnist.calculating_sse())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 88 iterations to converge\n",
      "Confusion Matrix:\n",
      " [[  0  10   0  13   1   0   1  20   8   0 469 537   1   1   0  51  15  27\n",
      "    2   0]\n",
      " [  0   1 462   9   1   2   4   0   0 461   0   0   0   2   0   3   0   6\n",
      "    4 410]\n",
      " [ 28  15   4  15   3  10  38  12   0   3   3   9 486 496   6   8  10  12\n",
      "    3   7]\n",
      " [  5 477   4 223   0   6  62   3  13   5   3   5  22  14   0  15 332   1\n",
      "   14   1]\n",
      " [384   0   3   3 444  34   3  12   0   3   0   1   6   0   1  38   0  21\n",
      "  246   7]\n",
      " [ 24  82   2  49   4   3   4  13 356   3   9  13   1   0   0 248 232  14\n",
      "    5   2]\n",
      " [  6   0   2   3   1   0   0 528   6   0  14  10   1   7   0  16   6 580\n",
      "    0   1]\n",
      " [ 82   0  14   2  20 483   3   1   0  15   7   3   4   7 497  10   2   0\n",
      "  100  12]\n",
      " [ 11  34   9 327  13  10 562   7  29   8   8   4   5   3   0  50  86   4\n",
      "   14   8]\n",
      " [288   3   5  18 213 203   1   1   4   5   5   4   3   0  17   6   6   1\n",
      "  417   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.616394379856563, 0.6810728709629809, 0.6440027444173391, 0.7295204972366178, 0.719192869263412, 0.7769941771722539, 0.5584125165530152, 0.6871692606759577, 0.6933978199180217, 0.7613527722179894, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      " Average Gini Index: 0.69\n",
      "\n",
      " Purity of the Cluster: 0.40\n",
      "\n",
      " Sum Of Squares: 4349024.49\n"
     ]
    }
   ],
   "source": [
    "kmeans_fashion_mnist = KMeans(20,5000)\n",
    "kmeans_fashion_mnist.fit(X_train)\n",
    "predict = kmeans_fashion_mnist.predict(X_test)\n",
    "kmeans_fashion_mnist.evaluate(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of Objective Function for K=20 is: 4349024.49\n"
     ]
    }
   ],
   "source": [
    "print(\"Value of Objective Function for K=20 is: %.2f\"% kmeans_fashion_mnist.calculating_sse())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans for 20 News Group Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english',max_features=10000,token_pattern='[A-Za-z]+',use_idf=False)  # Remove stopwords and apply TF-IDF\n",
    "ng_group_tf_vector = vectorizer.fit_transform(newsgroups_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(ng_group_tf_vector,newsgroups_data.target,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data: (15076, 10000)\n"
     ]
    }
   ],
   "source": [
    "print('Size of training data:',X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test data: (3770, 10000)\n"
     ]
    }
   ],
   "source": [
    "print('Size of test data:',X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_20ng = KMeans(n_clusters=20,metric='cosine',max_iter=100,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 44 iterations to converge\n"
     ]
    }
   ],
   "source": [
    "kmeans_20ng.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 40   1 168   8  19  83  29  22 112   8   3  42   4  69   8  25   0   5\n",
      "    4   3]\n",
      " [ 34  35  74  60  70  63  39   3   0  56   1  61  57   6  15  26  75  40\n",
      "    4  62]\n",
      " [ 35  34  77  20  31  57  45   5   3  36   1  23  27   5   5  20 286  41\n",
      "   15  28]\n",
      " [ 32  35  88  12  44  69  43   7   0  14   1  29  52   5  14  25  40  47\n",
      "  160  50]\n",
      " [ 44  33 100  13  61  96  55   8   0  19   0  40  43   8  26  25  18  37\n",
      "  113  18]\n",
      " [ 28  23  69  23  39  48  26   6   1  22   1  24  31   6   6  21  55  51\n",
      "    0 300]\n",
      " [ 37  59  39  17  12  58  43   3   3  41  13  20  26   4 220  20  20  16\n",
      "   82  55]\n",
      " [ 74  18 139  22  24 162  29  17   3  12   3  36  19  28 111  55   2  24\n",
      "    9   6]\n",
      " [ 61  11 169  20  22 146  62  23   7  12   5  54  19  15  59  65   3  16\n",
      "   14   3]\n",
      " [ 51  22 129  18  19 177  27  24   2  20 183  33  16  13  16  37   0   6\n",
      "    1   0]\n",
      " [ 58  12 116  15  18 133  32  18   4   8 319  17   9  16   7  18   1   1\n",
      "    0   0]\n",
      " [ 44  18 151  25  30 139  35  13   5  20   1  44   9  82  14  36   6 106\n",
      "    2   3]\n",
      " [ 57  20 128  25  57 102  45   5   1  30   2  84  38  12  28  48   5  74\n",
      "   13  18]\n",
      " [ 81  19 157  12  33 131  29  17   5  16   4  91  26  56  23  51   2  29\n",
      "    0   3]\n",
      " [ 60  14 144  30  27 160  32  18   5  27   2 113  21  23  20  57   5  24\n",
      "    3   9]\n",
      " [ 25   9  80  15  26  94  25  28 320   8   1  40   8  67   5  29   1   9\n",
      "    0   0]\n",
      " [ 48   5 194  17  19 142  30  44  11  17   2  39   5 106   8  34   1  16\n",
      "    0   1]\n",
      " [ 39   1  97   7  30 119  11  40  14  14   5  34   4 283   5  44   0   5\n",
      "    0   4]\n",
      " [ 33   6 148  17   8 138  18  34   4   9   3  37   3 129  13  26   1  18\n",
      "    1   1]\n",
      " [ 38   4  94   6  12  49  25  32  93   2   4  31   2  60   7  27   1   8\n",
      "    0   0]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.8631337518673386, 0.9278888322368152, 0.8374616931774201, 0.9061192713105293, 0.9141766236395142, 0.8203451676528599, 0.8805335102682368, 0.8851854737782838, 0.8852825204436416, 0.8570608277446085, 0.7832849298200882, 0.8870555498467596, 0.9123303744515866, 0.8905123940119275, 0.8858789789923165, 0.7951962826470117, 0.8566453221905036, 0.805013157526385, 0.8490166241050718, 0.8832649729619426]\n",
      "\n",
      " Average Gini Index: 0.87\n",
      "\n",
      " Purity of the Cluster: 0.25\n",
      "\n",
      " Sum Of Squares: 1451.22\n"
     ]
    }
   ],
   "source": [
    "predicted = kmeans_20ng.predict(X_train)\n",
    "kmeans_20ng.evaluate(y_train,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 21 iterations to converge\n",
      "Confusion Matrix:\n",
      " [[20  1 42 10  4 18  3  3 44  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [17 24 22 10 21 21 20  2  3 52  0  0  0  0  0  0  0  0  0  0]\n",
      " [13 12 26 13 14 21 12  1  4 75  0  0  0  0  0  0  0  0  0  0]\n",
      " [16 17 26 10 17 31 20  2  1 75  0  0  0  0  0  0  0  0  0  0]\n",
      " [33  2 21 21 23 26 16  4  3 57  0  0  0  0  0  0  0  0  0  0]\n",
      " [12 83 13 17 15 20  7  2  2 37  0  0  0  0  0  0  0  0  0  0]\n",
      " [56 12 16 16  2 24  8  1  2 50  0  0  0  0  0  0  0  0  0  0]\n",
      " [58  3 41 21  9 32 10  7  3 13  0  0  0  0  0  0  0  0  0  0]\n",
      " [54  1 42 20  6 55 14  5  5  8  0  0  0  0  0  0  0  0  0  0]\n",
      " [49  0 50 12  8 58  4 10  5  4  0  0  0  0  0  0  0  0  0  0]\n",
      " [51  0 39 15  7 66  6  6  6  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [21  5 71  6  8 53 12  2 20 10  0  0  0  0  0  0  0  0  0  0]\n",
      " [42  3 30 23 22 28 18  1  2 23  0  0  0  0  0  0  0  0  0  0]\n",
      " [38  3 45 16 21 45  8  6 14  9  0  0  0  0  0  0  0  0  0  0]\n",
      " [47  2 39 21  5 36 10  7 14 12  0  0  0  0  0  0  0  0  0  0]\n",
      " [13  0 35 14  9 29  8  6 91  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [20  1 45 11  0 42  3 17 29  3  0  0  0  0  0  0  0  0  0  0]\n",
      " [18  1 31  3  6 34  4 13 74  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [10  1 36  5  3 36  4 11 22  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [23  2 29  5  5 17  6  4 41  1  0  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.7860761869018578, 0.8522135416666666, 0.7921931964584303, 0.8139318550567874, 0.8418795362428126, 0.7794471153846153, 0.8015099087763448, 0.8215104743745008, 0.8083446712018141, 0.78425]\n",
      "\n",
      " Average Gini Index: 0.42\n",
      "\n",
      " Purity of the Cluster: 0.31\n",
      "\n",
      " Sum Of Squares: 302.52\n"
     ]
    }
   ],
   "source": [
    "kmeans_20ng = KMeans(n_clusters=10,metric='cosine',max_iter=100,batch_size=100)\n",
    "kmeans_20ng.fit(X_train)\n",
    "predict = kmeans_20ng.predict(X_test)\n",
    "kmeans_20ng.evaluate(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of Objective Function for K=20 is: 302.52\n"
     ]
    }
   ],
   "source": [
    "print(\"Value of Objective Function for K=20 is: %.2f\"% kmeans_20ng.calculating_sse())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For K=25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 45 iterations to converge\n",
      "Confusion Matrix:\n",
      " [[ 8  2  8  6  5 12  2  2 20  0  1  7  1  4  2  5  0  0  0  1 15  3 17  2\n",
      "  23]\n",
      " [ 6  7  3 22 14 14 12  2  3  7  2  9 15  4  0  4 10  4  0 20  1  9 12  5\n",
      "   7]\n",
      " [ 8  6  4  4 10  8  7  1  3  8  0  3  5  2  1  9 56  4  3  7  0 12 12  7\n",
      "  11]\n",
      " [ 4  6  3  2  7 19  9  1  1 35  0  6  7  5  7  5  9  6 35 10  0  3 10 14\n",
      "  11]\n",
      " [ 9  6 10  8 18 15  8  1  3 13  0  8 12  4  5  9  0 12 30  1  0  2 13 13\n",
      "   6]\n",
      " [ 5 10  7  5  7 14  7  0  1  2  3  4  5  5  1 11 14  9  1 75  0  6  3  6\n",
      "   7]\n",
      " [ 7 25  2  3  2 15  4  1  2  4  3  7  7  3 39  7  4  3 16  9  0 10  5  0\n",
      "   9]\n",
      " [17  2 14  4  8 20  8  5  2  2  0  4  5  6 26 14  0  2  3  3  1  6 15  9\n",
      "  21]\n",
      " [10  0 21  5  3 41 16  4  7  1  0  4  4 10 13 16  0  1  3  1  2  9 16  1\n",
      "  22]\n",
      " [14  3  5  3  5 40  2  6  2  0 53  3  3  6  2  7  0  0  0  0  2  4 18  0\n",
      "  22]\n",
      " [13  1  5  4  2 33  5  5  4  0 65  1  4  8  2  8  0  0  0  0  1  3 13  1\n",
      "  19]\n",
      " [ 6  3  4  2  3 28  8  0 13  0  0  5  1  9  1  3  1 60  0  1  0  4 23  0\n",
      "  33]\n",
      " [ 7  8  8  6 11 20 13  1  2  2  0  6 10 10  7 15  1 18  4  1  0  8 13  6\n",
      "  15]\n",
      " [34  5  4  6 15 32  4  2  7  0  0  8 10 13  2  7  0  4  0  1  2  6 15  8\n",
      "  20]\n",
      " [11  4 11  5  2 28 10  4  9  0  1  8  4 10  7 20  0  5  0  2  1 13 25  1\n",
      "  12]\n",
      " [ 6  3  4  4  6 25  6  5  7  0  0  2  2  9  2  9  1  0  0  0 80  2 24  0\n",
      "  10]\n",
      " [ 4  1  6  3  0 30  3 13 26  0  0  5  1 10  4  7  0  8  0  1  3  4 17  1\n",
      "  24]\n",
      " [ 3  1  9  3  4 25  3 10 76  0  0  4  0  2  2  3  0  2  0  0  4  6 13  1\n",
      "  13]\n",
      " [ 3  1  4  1  2 30  4  9 19  0  0  4  0  4  3  3  0  1  0  1  0  1 17  1\n",
      "  20]\n",
      " [ 8  2  4  3  3 13  6  4  7  0  0  6  0  6  2  4  0  2  0  1 31  3 15  0\n",
      "  13]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]]\n",
      "\n",
      " Gini Index Per Cluster:\n",
      "  [0.910958904109589, 0.9366861979166666, 0.8846796962802554, 0.9170362358031369, 0.9334055990197002, 0.8444896449704142, 0.9082901998913323, 0.9273106753588085, 0.9099319727891156, 0.8587, 0.8380530289365868, 0.8510539940828403, 0.9387478298611112, 0.9123616894705532, 0.923031490778276, 0.810894069873276, 0.8986696761396669, 0.7916469754253308, 0.869873046875, 0.8963762790434734, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      " Average Gini Index: 0.89\n",
      "\n",
      " Purity of the Cluster: 0.23\n",
      "\n",
      " Sum Of Squares: 374.48\n"
     ]
    }
   ],
   "source": [
    "kmeans_20ng = KMeans(n_clusters=25,metric='cosine',max_iter=100,batch_size=100)\n",
    "kmeans_20ng.fit(X_train)\n",
    "predict = kmeans_20ng.predict(X_test)\n",
    "kmeans_20ng.evaluate(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of Objective Function for K=20 is: 374.48\n"
     ]
    }
   ],
   "source": [
    "print(\"Value of Objective Function for K=20 is: %.2f\"% kmeans_20ng.calculating_sse())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
